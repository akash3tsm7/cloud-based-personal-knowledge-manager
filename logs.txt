Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
Traceback (most recent call last):
  File "/app/embedding_service.py", line 2, in <module>
    from FlagEmbedding import BGEM3FlagModel
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/__init__.py", line 2, in <module>
    from .inference import *
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/__init__.py", line 2, in <module>
    from .auto_reranker import FlagAutoReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/auto_reranker.py", line 5, in <module>
    from FlagEmbedding.inference.reranker.model_mapping import (
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/__init__.py", line 1, in <module>
    from .decoder_only import FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py", line 2, in <module>
    from .layerwise import LayerWiseLLMReranker as LayerWiseFlagLLMReranker
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py", line 15, in <module>
    from .models.modeling_minicpm_reranker import LayerWiseMiniCPMForCausalLM
  File "/usr/local/lib/python3.10/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py", line 53, in <module>
    from transformers.utils.import_utils import is_torch_fx_available
ImportError: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/site-packages/transformers/utils/import_utils.py)
